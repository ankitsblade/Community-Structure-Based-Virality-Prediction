# ğŸ§µ Community-Structure-Based Virality Prediction

Predicting whether a Reddit post becomes **micro-viral** or **viral** using:

* Multi-subreddit cascade extraction
* Community structure analysis
* Early cascade dynamics
* Classical ML models
* Graph Neural Networks (GraphSAGE)

This repository provides the full, modular pipeline for collection, processing, analysis, and visualization.

---

## ğŸ“ Project Structure

```
Community-Structure-Based-Virality-Prediction/
â”‚
â”œâ”€â”€ collect_cascades.py       # Multi-subreddit Reddit data collection
â”œâ”€â”€ run_pipeline.py           # Feature engineering + classical ML analysis
â”œâ”€â”€ run_gnn.py                # GraphSAGE training (optional)
â”‚
â”œâ”€â”€ microviral/
â”‚   â”œâ”€â”€ config.py             # Subreddit list, constants, thresholds
â”‚   â”œâ”€â”€ logger.py             # Logging setup
â”‚   â”œâ”€â”€ reddit_client.py      # PRAW client + submission fetcher
â”‚   â”œâ”€â”€ cascades.py           # Post â†’ cascade node extraction
â”‚   â”œâ”€â”€ graphs.py             # User graph + Louvain communities
â”‚   â”œâ”€â”€ features.py           # Feature extraction + virality labeling
â”‚   â”œâ”€â”€ models_ml.py          # Logistic Regression + Random Forest
â”‚   â”œâ”€â”€ visuals.py            # All plots
â”‚   â”œâ”€â”€ data_io.py            # Save/load utilities
â”‚   â””â”€â”€ gnn.py                # GraphSAGE architecture + dataset builder
â”‚
â”œâ”€â”€ data/                     # Cached cascade datasets
â””â”€â”€ figures/                  # Generated visualizations
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Create the virtual environment with **uv**

```bash
uv sync
```

This:

* Creates `.venv/`
* Installs **all dependencies** listed in `pyproject.toml`
* Sets up the environment exactly as needed
  No manual `pip install` steps are required.

---

### 2ï¸âƒ£ Configure Reddit API

Create a `.env` file in the project root:

```
CLIENT_ID=...
CLIENT_SECRET=...
USERNAME=...
PASSWORD=...
USER_AGENT=microviral_app:v1.0
```

---

## ğŸ•¸ï¸ Data Collection (Multi-Subreddit)

Fetch cascades across configured subreddits:

```bash
python collect_cascades.py
```

Output:

```
data/nodes_multi.parquet
```

---

## ğŸ§® Classical ML + Community Analysis Pipeline

```bash
python run_pipeline.py
```

This script:

* Builds global user graph
* Detects Louvain communities
* Extracts cascade + community features
* Labels cascades (micro-viral vs viral)
* Trains baseline ML models
* Saves all plots to `figures/`

---

## ğŸ§  Graph Neural Network (Optional)

```bash
python run_gnn.py
```

* Builds PyTorch Geometric dataset
* Trains GraphSAGE on cascade graphs
* Reports train/val/test ROC-AUC

---

## ğŸ§© What the Pipeline Does (Short)

* Collect Reddit cascades
* Build unified node-level dataset
* Model early community structure
* Extract features & label cascades
* Train models (LogReg, RF, GNN)
* Compare performance across subreddits
* Generate ROC curves, feature importance, and cascade visuals

---

## ğŸ“Š Example Outputs

Saved to `figures/`:

* Per-subreddit ROC curves
* Virality model comparison curves
* Feature importance plots
* Cascade graphs
* Mock result generators for poster creation

---

## ğŸ“œ License

MIT License.

